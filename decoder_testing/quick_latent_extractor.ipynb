{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import scipy.io\n",
    "from scipy.io import savemat\n",
    "os.chdir('/home/cyberspace007/mpicek/NeuralMAE')\n",
    "import neuralmae.neural_models.models_multimodal_neuralmae_up2 as models_mae_multimodal\n",
    "import neuralmae.neural_models.models_neuralmae_bsi as models_mae\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset shape: (10962, 32, 24, 10)\n"
     ]
    }
   ],
   "source": [
    "folder = '/media/cyberspace007/T7/martin/dt5/results/day_9/rec2/'\n",
    "input_path = os.path.join(folder, 'all.mat')\n",
    "output_path = os.path.join(folder, 'DINO_SSL_small_weight_10.mat')\n",
    "multimodal = True\n",
    "\n",
    "# lost files that were recomputed later needed to be opened this way :)\n",
    "all_data = scipy.io.loadmat(input_path)['x']\n",
    "all_data = np.transpose(all_data, (0, 3, 2, 1))\n",
    "\n",
    "\n",
    "# all_data = h5py.File(input_path)['X'] # FIXME\n",
    "print(f\"dataset shape: {all_data.shape}\")\n",
    "# expected shape: (n_samples, 32, 24, 10) .. n_samples = 10*seconds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prepare_pretrained_brainGPT(chkpt_dir, arch='mae_neut_base_patch245_1implant'):\n",
    "    #build model\n",
    "    model = getattr(models_mae, arch)()\n",
    "\n",
    "    #load model\n",
    "    chkpt = torch.load(chkpt_dir, map_location='cpu')\n",
    "    msg = model.load_state_dict(chkpt['model'], strict=False)\n",
    "    print(msg)\n",
    "    return model\n",
    "\n",
    "def prepare_pretrained_brainGPT_multimodal(chkpt_dir):\n",
    "\n",
    "    freeze_brainGPT = False\n",
    "    # 'mae_neut_conf_tiny_multimodal_mlp_delta_DINO'\n",
    "    # model = models_mae_multimodal.__dict__['mae_neut_conf_tiny_multimodal_mlp_accelerometer'](norm_pix_loss=False,\n",
    "    model = models_mae_multimodal.__dict__['mae_neut_conf_tiny_multimodal_mlp_delta_DINO'](norm_pix_loss=False,\n",
    "                                                    norm_session_loss=True,\n",
    "                                                    uniformity_loss=False,\n",
    "                                                    lamb=0.01,\n",
    "                                                    # input_size=tuple(args.input_size), \n",
    "                                                    # patch_size=tuple(args.patch_size),\n",
    "                                                    use_projector=False,\n",
    "                                                    projector_dim=64,\n",
    "                                                    freeze_brainGPT=freeze_brainGPT)\n",
    "\n",
    "    checkpoint = torch.load(chkpt_dir, map_location='cpu')\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters of the BrainGPT: 110.970265 M\n",
      "Number of parameters of the DINO MLP Projector: 6.039552 M\n",
      "Multimodal BrainGPT model loaded.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if multimodal:\n",
    "    # Multimodal BrainGPT (accelerometer)\n",
    "    # chkpt_dir = \"/media/cyberspace007/T7/tmp/training_logs/neuralmae/checkpoints/MLP_predict_ACC_NOT_frozen_BrainGPT/checkpoint-10.pth\"\n",
    "    chkpt_dir = \"/media/cyberspace007/T7/tmp/training_logs/neuralmae/checkpoints/MLP_predict_DINO_NOT_frozen_BrainGPT_25mask_small_weight/checkpoint-10.pth\"\n",
    "    model_mae = prepare_pretrained_brainGPT_multimodal(chkpt_dir)\n",
    "    print('Multimodal BrainGPT model loaded.')\n",
    "else:\n",
    "    # Vanilla BrainGPT\n",
    "    chkpt_dir = '/home/cyberspace007/mpicek/NeuralMAE/pretrained_brainGPT/checkpoint-14_up2001.pth'\n",
    "    model_mae = prepare_pretrained_brainGPT(chkpt_dir, 'mae_neut_base_patch245_1implant')\n",
    "    print('Vanilla BrainGPT model loaded.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10962/10962 [01:36<00:00, 113.90it/s]\n"
     ]
    }
   ],
   "source": [
    "# extract latents\n",
    "from tqdm import tqdm\n",
    "device = torch.device('cuda:0')\n",
    "model_mae = model_mae.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    model_mae.eval()\n",
    "    inputs, latents, targets, sessions = [], [], [], []\n",
    "\n",
    "    for i in tqdm(range(all_data.shape[0])):\n",
    "        # print(f'epoch {i+1}/{all_data.shape[0]}, ', end='')\n",
    "        epoch_wavelet = np.transpose(all_data[i,:,:,:], (1, 0, 2))[:,:32,:]\n",
    "        samp = torch.from_numpy(epoch_wavelet).to(device, non_blocking=True, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            if multimodal:\n",
    "                lat = model_mae.brainGPT.transform(samp, mask_ratio=0)\n",
    "            else:\n",
    "                lat = model_mae.transform(samp, mask_ratio=0)\n",
    "            latents.append(lat)\n",
    "\n",
    "    latents = np.concatenate(latents, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank latent: 408.8719482421875\n",
      "(10962, 768)\n"
     ]
    }
   ],
   "source": [
    "def rankme(Z):\n",
    "    \"\"\"\n",
    "    RankMe smooth rank estimation\n",
    "    from: https://arxiv.org/abs/2210.02885\n",
    "\n",
    "    Z: (N, K), N: nb samples, K: embed dim\n",
    "    N = 25000 is a good approximation in general\n",
    "    \"\"\"\n",
    "\n",
    "    S = torch.linalg.svdvals(Z) # singular values\n",
    "    S_norm1 = torch.linalg.norm(S, 1)\n",
    "\n",
    "    p = S/S_norm1 + 1e-7 # normalize sum to 1\n",
    "    entropy = - torch.sum(p*torch.log(p))\n",
    "    return torch.exp(entropy)\n",
    "\n",
    "print(f'rank latent: {rankme(torch.from_numpy(latents))}') # ~2x4x10\n",
    "print(latents.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save latents as .mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latent features saved to /media/cyberspace007/T7/martin/dt5/results/day_9/rec2/DINO_SSL_small_weight_30.mat\n"
     ]
    }
   ],
   "source": [
    "\n",
    "struct_name = 'xLatent'\n",
    "savemat(output_path, {struct_name: latents.transpose()})\n",
    "print(f'Latent features saved to {output_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural_mae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
